<aside>

- **Executive Summary**
    
    **Chapter 1 - J-Curves & the Solow Paradox**.  We’re still early on the J-curve—firms are stockpiling intangibles such as data assets, skill formation, and workflow re-engineering that GDP hasn’t caught yet, but a shartp productivity rebound lies ahed.
    
    **Chapter 2 - Knowledge Formation & Intangibles**. Cheap ideas invert scarcity: evaluation capacity becomes the bottleneck—demanding perpetual upskilling and agile experimentation.
    
    **Chapter 3 – Skills of the Future.** Product-first AI engineering—built on a data-mesh principles—pairs board-level oversight with autonomous squads that iterate, ship, and sell at startup speed.
    
    **Chapter 4 – Disrupt or Be Disrupted.** GenAI rewards startup speed—pressuring incumbents to slash red tape and gatekeeper roles, build intangibles from data fundamentals upward, and out-innovate their own business models before rivals do.
    
    **Chapter 5 – Strategic Scenarios & Trade-offs.** Simulations reveal that steady investment, dynamic R&D-production pivots, disciplined idea triage, and selective competition consistently outperform their counterparts.
    
    **Chapter 6 – Code & Math.** A documented open-source repo exposes every equation and simulation, letting you reproduce results, tweak parameters, and run new scenarios at will.
    
</aside>

GenAI makes ideas cheaper, but the capacity to distinguish signal from noise is scarce.

[**Top laboratories using generative AI for research](https://arxiv.org/abs/2412.17866)** discovered **44% more materials** and achieved a **17% rise in product innovation**. 

As genAI breakthroughs spread into law, education, and politics, they will rewrite the rules.

“Not so fast,” you might reply. Even when the tech exists, change takes time. 

The study also reveals a blind spot: smaller labs lack the skills to tell **promising AI-generated ideas** from **dead ends**.

Confirming the point: [**U.S. firms’ genAI roll-outs have doubled, yet 75% still can’t scale their proofs of concept**](https://www.bain.com/insights/survey-generative-ai-uptake-is-unprecedented-despite-roadblocks) due to a lack of expertise. **Gatekeeper team members drag momentum** even further.

Meanwhile, Big Tech [fuels CapEx at historic levels](https://www.sequoiacap.com/article/ais-600b-question/)[,](https://www.sequoiacap.com/article/ais-600b-question) funding data centers, models, and chips, positioning themselves as *arbiters* of productivity gains.

Simultaneously, all that spending and decades of research have created a **new division of labor.** Models handle the groundwork, humans frame directions, run experiments, and assess outcomes. 

The puzzle is no longer *whether* genAI matters, but *who* can harness it—and *how*.

# 1. J-curves and the Solow Paradox

> "*You can see the computer age everywhere but in the productivity statistics*" 
**Robert Solow**
> 

[ChatGPT rocketed to mass adoption](https://www.forbes.com/sites/martineparis/2025/04/12/chatgpt-hits-1-billion-users-openai-ceo-says-doubled-in-weeks) and genAI is a revolution, so why doesn’t GDP show it?

The '*Solow Paradox*' attributes the AI-productivity gap to [**inputs GDP misses**](https://academic.oup.com/oxrep/article/37/3/435/6374681)—software, data, training, and organizational redesign.

It’s the [**productivity J-curve**](https://ide.mit.edu/sites/default/files/publications/2019-04JCurvebrief.final2_.pdf): output dips while firms build those hidden assets; once they mature, productivity snaps back and rises.

U.S. data show plenty of intangible spending, but [**no hint of that rebound**](https://academic.oup.com/oxrep/article/37/3/435/6374681) through 2017.

Since OpenAI’s first LLM was in 2018, we remain early on the J curve’s leg, as rapid model improvements have outpaced organisational adaptation.

# 2. Knowledge Formation & Intangibles

> "*We must take seriously the economic opportunities presented by the potential for producing new ideas"*
**Paul Romer**
> 

Romer formalised the proverb “**standing on the shoulders of giants**”, showing that cumulative ideas fuel economic growth.

1. **Knowledge is non-rival**: when one person uses an idea, everyone else can use it at zero extra cost;
2. **Knowledge compounds**: each discovery integrates with the existing stock of ideas, expanding the knowledge base for the next growth wave.

As ideas proliferate faster than experts can scrutinise them, unverified knowledge competes for limited attention:

| Phase | Canonical view | Technological shift | Emergent scarcity |
| --- | --- | --- | --- |
| Generation | Costly R&D; **producing new ideas is the engine of growth** | LLMs reduce marginal cost of drafts | High-quality ideas depend on filters |
| Evaluation | Bundled into the R&D cost | Hypothesis framing & validation is expert-intensive | **Evaluation capacity** |
| Rivalry | Ideas non-rival; capital & labour rival | Raw ideation is plentiful | **Experimentation culture** |

In this shift, key challenges involve:

- **Organizational Know-How**. Are processes innovation-friendly, and roles like **GenAI Engineer** and **Chief GenAI Officer** established?
- **Workforce Skills**. Do teams have sufficient **training** and **dedicated time** to experiment with new tools?
- **Culture** **&** **Leadership**. Is leadership implementing a genAI strategy? Do **risk-averse managers, skeptical employees**, or short-term targets undermining it?

# 3. Skills of the Future

Chip Huyen’s [newest book](https://www.amazon.com/AI-Engineering-Building-Applications-Foundation/dp/1098166302) distills the generative-AI stack into three layers:

| Domain | Purpose | **Expertise leveraged** | Core tasks |
| --- | --- | --- | --- |
| **Application Development** | Uses existing models to build products | Product-oriented mindset | Interface design; Prompt engineering; Context construction; Evaluation |
| **Model Development** | Creates foundation models | Traditional Data Science | Dataset engineering; Model training; Fine-tuning; inference optimisation; Evaluation |
| **Infrastructure** | Provides the runtime backbone for models and apps | MLOps & Data Engineering | Model & app serving; Data-and-compute management; Monitoring |

Huyen outlines the priority flip between ML and AI engineering.

**ML Engineering**: *Data* → Model → Product

**AI Engineering**: *Product* → Data → Model

Chemistry Nobel marks model-side progress: [a transformer that predicts protein structures](https://www.science.org/doi/10.1126/science.370.6521.1144).

However, the greatest opportunities lie in the application layer, where moving from **model-first to product-first** unlocks new specialties.

Applying **data-mesh principles** enables **competitive advantages** in this app layer:

<aside>

**Evaluation capacity** **(EC)** — **triage**, **test**, and **trace** genAI applications on a unified observability-and-metrics platform. 

A *cross-functional board*, backed by *redesigned governance*, applies domain expertise and executive judgment to prioritise high-value problems and steer resources.

**Experimentation culture** **(ExC)** — **generate**, **orchestrate**, and **iteratively refine** genAI ideas to product-market fit *startup style*. 

*Autonomous*, *product*-centric squads apply *design thinking* and *lean build–measure–learn* loops to test, prototype, launch and sell products.

</aside>

GenAI will [reinvent programming](https://www.oreilly.com/radar/the-end-of-programming-as-we-know-it/) and [team design](https://www.svpg.com/a-vision-for-product-teams/); in turn, autonomous agents will re-architect the data lifecycle, from data modelling and infrastructure-as-code to platform migrations, CI/CD, governance, and ETL pipelines.

# 4. Disrupt or Be Disrupted

GenAI reshapes competition unevenly.

**Startups enjoy a blank slate**: no legacy workflows, iteration is fast, and freedom to design every process and product around genAI from day one.

**Big companies must move early**:

1. **Slashing red tape** — flatten middle-management layers and empower developers;
2. **Invest in intangibles** — start with data-engineering fundamentals, classic ML, and agile governance;
3. **Attract talent** — hire engineers with technical chops and creative, experimental mindsets offering what startups lack: stability and scale.

Partnerships will surge as start-ups and big companies bring complementary strengths to the table.

A broad wave of **creative destruction** is coming for a wide range of [business models](https://www.horsesforsources.com/sas_1-5-trillion-dollar-opportunity_020725).

As [**Y Combinator often reminds founders**](https://www.youtube.com/watch?v=CBYhVcO4WgI&list=PL5q_lef6zVkaTY_cT1k7qFNF2TidHCe-1), the best ideas often look “obviously bad” like Airbnb.

**Lesson**: disrupt your own business model before someone else does.

# 5. **Strategic Scenarios & Trade-offs**

Nearly 1,000 micro-economic simulations (≈30M data points) revealed four patterns.

### a) Boom-and-bust vs. steady investment

Two capital-allocation styles in genAI: an early-peak “big-bang” spend followed by retrenchment, versus a steady, compounding out-lay.

- ***Boom-and-bust spending works only when the payoff window is predictable**.* If a genAI breakthrough is clearly timed and the firm already holds the needed intangibles, one bold up-front outlay can lock in a lasting advantage.
- **Steady investment pays off over a long horizon**: capital, talent, and capabilities grow together as automation unfolds gradually and predictably, being more resistant to crisis;

### b) Production vs. R&D

Balancing exploration (research) and exploitation (delivery) determines how quickly—and how long—genAI returns accrue.

- **Dynamic strategy is better**: firms that continually tune the production and R&D mix stay ahead and beats static plans;
- **If you start R&D-first**, pivot to production once a viable innovation is ready—especially when market disruption or first-mover advantage looms;
- **If you start production-first**, keep a baseline R&D budget and ramp discovery before growth plateaus, using early revenue to fund the next sprint.

### c) Triage and evaluation

How ideas are screened, tested, and promoted determines whether genAI initiatives accelerate—or stall.

- **Balanced Screening**: Objective rules that aren’t over-rigid prevent both innovation stagnation and overwhelming backlogs;
- **Blend perspectives**: Panels that pair generalists (breadth for navigating uncertainty) with specialists (depth for technical quality) deliver better reviews;
- **Move fast and don't break things**: Rapidly approve, build, and test to counter idea decay and rival’s copycats—but apply due diligence to avoid premature launch pitfalls.

### d) Co-operation vs. Competition

How firms share knowledge—or withhold it—shapes both total output and innovation spill-overs.

- **Collaboration grows the pie**: co-operative networks yield far higher total output than siloed rivalry;
- **Talent poaching cuts both ways**: hiring away key employees can create winner-takes-all gains, but turnover rises;
- **Labour mobility drives spill-overs**: when experts move between firms, they diffuse new ideas and boost innovation;
- **Blend openness and rivalry**: The optimal innovation ecosystem involves **shared basic research** but **competes fiercely on products**.

# 6. Code & Math

The open-source repository with simulations, code and equations is available [**here**](https://github.com/andreichiro/genAI/blob/main/README.md).

You can reproduce the baseline runs **or plug in your own company data to model scenarios**.

At the heart of the **ECB model** lies an S-shaped curve that **converts evaluator headcount and skill into end-to-end evaluation capacity**—ideation to final verdict, meetings and partial reviews included—until **congestion of expert attention** stalls the flow.

$$
Utot,i = Uf,i+ξ1Unf,iHnf,iζskill,
$$

$$
Ψraw,i(Utot,i)=  ψ0+1+exp[−κ(Utot,i−U∗)]ψmax−ψ0,
$$

$$
Ψeff,i = 1+ηcongestionU−iΨraw,i(Utot,i)
$$

| Symbol | Interpretation |
| --- | --- |
| $(U_{f,i})$ | *Fungible* evaluation capital (e.g., scalable infrastructure, tools, observation-metrics platform) |
| $(U_{nf,i})$ | Non-fungible evaluator capital—the headcount of in-house experts whose skills are not easily rented  |
| $(H_{nf,i})$ | Skill level of those evaluators |
| $(xi_{1}>0), (zeta_{text{skill}}in(0,1])$ | Multipliers that translate evaluator headcount and skill into effective capital |
| $(psi_{0}), (psi_{max})$ | Baseline screening throughput and its maximum attainable ceiling, respectively |
| $(U^{*})$ | The amount of total evaluation capital at which throughput reaches half of its maximum |
| $(\kappa)$ | Steepness of the S-curve, controls how quickly throughput rises as evaluation capital increases |
| $(eta_{congestion}ge 0)$ | Sensitivity to industry congestion |
| $(overline{U}_{-i})$ | Average total evaluation capital across ****all ****rival ****firms in the industry |

I’d love to discuss these ideas—feel free to [contact me](https://www.linkedin.com/in/andr%C3%A9-ichiro-82592327/).