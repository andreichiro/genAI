# Project Overview & Replication Guide  

## 1 . Quick start â€” zero-click reproduction

```bash
git clone <repo-url>
cd <repo>
python -m venv .venv && source .venv/bin/activate       # optional but recommended
pip install -r requirements.txt                         # pandas, numpy, matplotlib, etc.

# ğŸ” Run the entire pipeline (â‰ˆ 1â€“2 min on a laptop)
make reproduce              # or:  python replicate.py --jobs 4


## 2. genAI.py deep dive

compute_y_romer(â€¦)
This single routine can reproduce all of the model variants described, from a textbook Romer to AI-augmented versions with stochastic noise, adaptive time-steps, logistic intangible spill-overs and dynamic capital deepening.

2.1 Core objective

For each discrete period t = 0 â€¦ num_periods â€“ 1 it computes

Y_new(t) =  [L_Y(t)]^(1-Î±) Â· Î£_i  x_i(t)^Î± with   0 < Î± < 1

This is subject to the resource constraint:
Î£_i x_i(t)  =  K(t)

And under the influence of optional channels:
Knowledge stock A(t) â€“ grows through a user-supplied or built-in knowledge_updater;
Synergy and intangible scalars â€“ can scale the aggregator Cobb-Douglas style, or via a logistic accelerator;

synergy_cobb_douglas_on / intangible_cobb_douglas_on toggle the multiplicative Î³- and Î¶-powers.
synergy_cd_exponent and intangible_cd_exponent are those exponents (defaults 0.2 and 0.3).

Capital accumulation â€“ capital_updater can turn todayâ€™s output into tomorrowâ€™s capital;

Skill interaction â€“ set skill_interaction_on=True and pass a skill_interaction_func(t, synergy_t, intangible_t) that returns any non-negative scalar. The main loop multiplies Y by this factor each period (if you leave the flag False the extra call is completely skipped.)

All of these are pluggable callables. If you omit one, the function auto-fills a safe default so the solver never sees a None.

2.2 Parameter map (what you can configure)

Time horizon & technology:

num_periods (â‰¥1) â€“ length of the run.

alpha (0<Î±<1) â€“ elasticity of substitution â†’ also controls monopolistic-competition mark-up.

growth_explosion_threshold (default 10Â¹Â²) terminates the loop and raises GrowthExplosionError if either Y or A crosses it. Useful for sweeps that hit unstable corners of parameter space.

Numerical control:

dt_integration â€“ Euler step if you use the simple internal capital/knowledge ODEs.

adaptive_dt â€“ set True to auto-halve dt_integration whenever any state variable jumps by more than rel_change_tol (default 20 %).

dt_floor â€“ lower bound so the loop cannot shrink forever.

rel_change_tol sets what â€œtoo largeâ€ means for adaptive Î”t (default 0.20 â‡’ 20 %).

Stochastic ribbons:

monte_carlo_sigma â€“ log-normal Ïƒ applied multiplicatively to Y_new(t) after the deterministic pass.
â€“ growth_explosion (True/False) tells you if the run tripped the early-abort guard.
â€“ final_x_values echoes the last intermediate-goods vector so you can inspect variety counts or pass it as an initial condition to another run.

Setting it to zero keeps the model deterministic (the default).

rng â€“ an np.random.Generator or an integer seed for reproducible randomness.

Labour allocation:

labor_func(t) â€“ returns final-goods labour L_Y(t) if you do not use the split helpers.

total_labor_func(t) + share_for_rd_func(t) â€“ if provided, the engine itself splits labour into L_Y(t) and L_A(t) internally (needed for endogenous knowledge growth).

Capital:

capital_func(t) â€“ an exogenous path for K(t).

s_invest_rate, delta_capital â€“ if you prefer the classic law
KÌ‡ = sÂ·Y â€“ Î´Â·K without writing a custom updater.

capital_updater(t, K_prev, synergy, intangible, Y) â€“ full control over accumulation,
e.g. to inject an intangible premium into investment efficiency.

delta_capital pairs with s_invest_rate inside the default

capital ODE â†’ KÌ‡ = s Y â€“ Î´ K.
Leave both at 0 to switch the ODE off.

Knowledge:

knowledge_updater(t, A_prev, synergy, intangible, x_vals) â€“ your own law of motion.

If you leave it None, the function auto-selects one of three built-ins:

A partial-AI growth law if you specified phi_ai_rd>0 or fraction_ai_rd_func.

The classic Romer law AÌ‡ = Î´Â·AÂ·L_A if delta_knowledge>0.

A no-op updater that keeps A constant.

delta_knowledge is the Î´ in the classic Romer law
AÌ‡ = Î´ A L_A and is only used when no custom knowledge_updater is provided.

Intermediate-goods vector:

x_values_updater(t, x_prev, synergy, intangible, A, K) â€“ must return an array that sums to K.
If omitted we fall back to the symmetrical rule x_i = K/A.

x_values_init â€“ starting vector (default [1.0]).

Note x_values_init lets you start with a non-uniform
vector (e.g., calibrated from data) instead of the default [1.0].

Aggregator choice

aggregator_mode in { "classic", "zeira", "ces" } â€“ selects one of the three helper
functions at the end of the file:

Modes:
classic; zeira; ces

Classic: 	Standard Dixitâ€“Stiglitz
Zeira: 	    Partial automation (Zeira 1998). See fraction_automated_func
CES: 	    Constant-Elasticity-of-Substitution. See rho (Ïƒ = 1 / (1â€“Ï))

fraction_automated_func(t) feeds Î²(t) into the Zeira or CES mode.

rho controls the elasticity in the CES variant
(Ïƒ = 1 / (1 â€“ Ï)).

tfp_func(t) can override synergy and supply an arbitrary productivity time-series.

Synergy & Intangibles:

synergy_func(t) / intangible_func(t) â€“ any non-negative scalar series.

synergy_cobb_douglas_on, synergy_cd_exponent â€“ raise Y by synergy^Î³.

Same trio for intangibles.

intangible_logistic_on, intangible_kappa, intangible_Ubar, intangible_epsilon â€“ apply a bounded boost
Y â† YÂ·(1 + ÎµÂ·logistic(intangible)).

Skill interaction:

If skill_interaction_on is True, the custom skill_interaction_func(t, synergy, intangibles)
can inject an additional multiplicative term.

The routine returns a dictionary with the full trajectory (if store_results=True) and every final state, or just the finals if you only care about end-points.

2.3. Aggregator helpers
aggregator_classic â€“ implements the standard Romer aggregator
Y = A Â· L_Y^(1â€“Î±) Î£ x_i^Î±. tfp_val lets you bolt in synergy as pure TFP.

aggregator_zeira â€“ mirrors Zeiraâ€™s â€œpartial task automationâ€: a share Î²(t) of capital substitutes for labour. Setting beta=None collapses to a Cobbâ€“Douglas in K and L.

aggregator_ces â€“ flexible CES with exponent Ï â‰  0.
When Ïâ†’0 the expression converges to Cobbâ€“Douglas; when Ï<0 capital and labour are complements.

All three are pure functions: no side-effects, easy to unit-test.

3.3. Knowledge-only solvers
compute_knowledge_romer â€“ stand-alone Euler integrator for the old Romer law AÌ‡ = Î´ Â· A Â· L_A. Useful for sanity-checking the embedded updater.

compute_partial_knowledge_AI and compute_full_knowledge_AI â€“ two extensions that match the paperâ€™s partial-AI and full-AI specifications:

AÌ‡ = Î´ Â· A^Î¸ Â· [ L_A + Î³Â·K_AI,R ]^Î·       (partial)
AÌ‡ = Î´ Â· A^Î¸ Â· [ Î³Â·K_AI,R ]^Î·             (full)

Both accept callables for K_AI,R, Î³(t), synergy, intangibles, etc., then march forward with Euler steps of size dt.

Helper one-liners compute_A_dot_* concentrate the derivative so you can unit-test it separately.

3.5. Labour split utility

labor_split(â€¦) takes total labour and a share-to-R&D function and returns period-by-period
L_Y / L_A (and, if you pass a knowledge_updater, it updates A(t) along the way).

It is essentially a pre-processor so you donâ€™t have to write boiler-plate splitting logic in every scenario.

3.6. Convenience wrappers for AI scenarios

use_partial_ai â€“ injects a composite labour term LÌƒ = L_Y + Ï†(t)Â·K_AI(t) into the classic aggregator, so you can model AI capital augmenting human labour without editing the core solver.

use_full_ai â€“ extreme case where human labour is negligible; the wrapper feeds Ï†Â·K_AI as the â€œlabourâ€ input and sets L_Y = 0.

Both functions simply pre-configure the arguments and call compute_y_romer; they add no new maths.

3.7. Organisation-Capital module
compute_org_intang_capital(â€¦) implements the perpetual-inventory method of Eisfeldt & Papanikolaou (2013) with the option to:

feed in raw SG&A and CPI data series (you provide the callables),
apply a logistic saturation to mimic decreasing returns when the intangible stock approaches a threshold UÌ„(t),
inject extra intangible investment outside SG&A (e.g. your Phase-G trickle).

The default invocation with kappa_func = 0 and extra_invest_func = 0 reduces to the textbook formula: 

OC_{t+1} = (1 â€“ Î´)Â·OC_t  +  SGA_{t+1}/CPI_{t+1}.

3.8. How to use in practice

Write or load scenario callables â€“ import load_scenarios from scenarios.py; that returns a fully wired ScenarioCfg where every field is a ready-made lambda that ultimately points at the functions in this file.

Call the engine

from genAI import compute_y_romer
from scenarios import load_scenarios

cfg = load_scenarios()[0]               # grab first scenario
out = compute_y_romer(
        num_periods           = cfg.num_periods,
        alpha                 = cfg.alpha,
        labor_func            = cfg.labor_func,
        capital_func          = cfg.capital_func,
        synergy_func          = cfg.synergy_func,
        intangible_func       = cfg.intangible_func,
        x_values_updater      = cfg.x_values_updater,
        knowledge_updater     = None,            # or your own
        total_labor_func      = cfg.total_labor_func,
        share_for_rd_func     = cfg.share_for_rd_func,
        adaptive_dt           = True,
        monte_carlo_sigma     = 0.10,
        aggregator_mode       = "classic",
        growth_explosion_threshold = 1e10,
)

Note that setting adaptive_dt=False re-enables fixed Î”t even if rel_change_tol is provided.


Inspect results

df = pandas.DataFrame(out["outputs"])
df.plot(x="t", y="Y_new", logy=True)

